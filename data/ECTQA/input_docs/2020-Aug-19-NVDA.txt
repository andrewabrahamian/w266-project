Congratulations on the strong growth and execution. Jensen, I'm wondering how much of the strength that you're seeing in gaming and data center is maybe more temporary because COVID or some customer pull-ins in the data center or so forth? And how much of it is more structural and more secular that can continue even once we get into, hopefully, sooner rather than later, into a more normalized period for the industry?
Yes. Vivek, thank you. So first of all, we didn't see pull-ins, and we're in the beginning of our brand-new product cycle with Ampere. And so the vast majority of the data center growth came from that. The gaming industry, they -- with all that's happening around the world, and it's really unfortunate, but it's made gaming the largest entertainment medium in the world. More than ever, people are spending time digitally, spending on time -- spending their time in video games. The thing that people haven't realized about video games is that it's not just the game itself anymore. The variety of different ways that you can play, whether you can hang out with your friends in Fortnite, go to a concert in Fortnite, building virtual worlds in Minecraft, you're spending time with your friends, you're using it to create -- to realize your imaginations.
People are using it for broadcast, for sharing ideas and techniques with other people, and so -- and then of course, it's just an incredibly fun way to spend time even by consumption of the video -- of a video game. And so there's just so much that you could do with video games now. And I think that this way of enjoying entertainment digitally has been accelerated as a result of the pandemic, but I don't think it's going to return. Video game adoption has been going up over time and pretty steadily. PC is now the single largest entertainment platform -- is the largest gaming platform. And GeForce is now the largest gaming platform in the world. And as I mentioned, it's not just about gaming. There's just so many different ways that you could enjoy games.
With data center, the thing that -- the structural change that's happening in data center are a couple of different dynamics that are happening at the same time. The first dynamic, of course, is the movement to the cloud. The way that a cloud data center is built and the way that an enterprise data center or a cluster is built is fundamentally different. And it's really, really beneficial to have the ability to accelerate applications that cloud service providers would like to offer, which is basically everything. And we know that one of the most important applications of today is artificial intelligence. It's a type of software that really wants acceleration, and NVIDIA's GPU acceleration is the perfect medium, perfect platform for it.
And then the last reason about the data center is the architectural change from hosting applications to hosting services that's driving this new type of architecture called disaggregation versus hyper converged. And the original name of hyperscalers is a large data center of a whole bunch of hyperconverged computers. But the computers of today are really disaggregated. A single application service could be running on multiple servers at the same time, which generates a ton of east-west traffic, and a lot of it is artificial intelligence neuro network models.
And so because of this type of architecture, 2 components, 2 types of technologies are really important to the future of cloud. One of them, as I mentioned, was -- is acceleration, and our GPU is ideal for it. And then the other one is high-speed networking. And the reason for that is because the server is now disaggregated, the application is fractionalized and broken up into a bunch of small pieces that are running across the data center. And whenever an application needs to send parts of the answer to another server for the microservice to run, that transmission is called east-west traffic, and the most important thing you could possibly do for yourself is to buy really high-speed, low-latency networking. And that's what Mellanox is fantastic at.
And so we find ourselves really in this perfect condition where the future is going to be more virtual, more digital, and that's one -- that's the reason why GeForce is so successful. And then we find ourselves in a world where the future is going to be more autonomous and more AI-driven, and that's the benefit of our GPUs.
And then lastly, cloud microservice transactions really benefit high-speed networking, and that's where Mellanox comes in. And so I think that this is -- the dynamics that I'm describing are permanent, and it's just been accelerated to the present because of everything that's happening to us. But this is the future, and it's not -- there's no going back, and we just found everything accelerated.
Your next question comes from the line of Timothy Arcuri with UBS.
Jensen, I guess I had a question on both architecture and also manufacturing. And I think on the manufacturing side, you've been radical now for some time. And when you've been asked in the past about moving to more of a tiled or chiplet approach, you sort of made light of that. But the CPU guys are clearly taking that approach. So I guess the question is, why do you think you won't have to make a similar move? And then on the side of architecture, the theme of Hot Chips this week was really how compute demand is far outstripping computing power? And then we see this talk about you and ARM. So I guess can you talk about whether GPU is the future and maybe the broader opportunity to integrate CPU and GPU?
Yes. We push architecture really hard. And the way we push architecture is we start from the system, but we believe that the future computer company is a data center-scale company. The computing unit is no longer a microprocessor or even a server or even a cluster. The computing unit is an entire data center now. And as I was explaining to Vivek just now that a microservice that we're enjoying hundreds of billions of transactions a day, those are broken up into a whole bunch of microservices that are running across the entire data center.
And so the data center is running -- the entire data center is running an application. I mean that's pretty remarkable thing, and that's happened in the last several years. We were ahead of this trend, and we recognized that as a computing company, we have to be a data center-scale company, and we architect from that starting. If you look at our architecture, we were the first in the world to create the concept of an NVLink with 8 processors being fully synchronized across a computing node, and we created the DGX.
We recognize the importance of high-speed networking and low-latency networking, and that's why we bought Mellanox. And the amount of software that we invented along the way to make it possible for low-latency communications, whether it's GPUDirect or recently the invention of GPUDirect Storage, all of that technology was inspired by the idea that you have to think about the data center all-in-one holistic way.
And then in the last -- in this current generation with Ampere, we invented the world's first multi-instance GPU. We invented the world's first multi-instance GPU, which means that our Ampere GPU could simultaneously be 1 GPU or, with NVlink, 8 GPUs combined, working together, so you could think of them as being tiled. So those 8 GPUs are working harmoniously together. Or each one of the GPUs could fractionalize itself, if you don't need that much GPU working on your workload, fractionalize into a multi-GPU instance, we call the MIG, a little tiny instance. And each one of those tiny instances are more powerful and more performant than our entire Volta GPU lap time. And so whether you like to fractionalize the GPU, which happens oftentimes; create a larger GPU using NVLink; or create an even larger GPU, the size of DGX POD, connected together with high-speed, low-latency networking with Mellanox, we could architect it any way you'd like.
You made a comment about -- you asked a question about ARM. We've been a long-term partner of ARM, and we use ARM in a whole bunch of applications. And whether it's autonomous driving or a robotics application, the Nintendo Switch, console business that we're in. And then recently, we brought CUDA to ARM and to bring accelerated computing to ARM. And so we worked with the ARM team very closely. They're really great guys. And one of the specials about the ARM architecture that you know very well is that it's incredibly energy-efficient. And because it's energy-efficient, it has the headroom to scale into very high-performance levels over time. And so anyways, we love working with the ARM guys.
Your next question comes from the line of Aaron Rakers with Wells Fargo.
Congratulations on the quarter. Just building on some prior questions. The first one, I was just curious if you could help us appreciate kind of the installed base of the gaming GPU business relative to where we're at the Turing upgrade cycle. What do we see still on prior generations, be it Pascal or before? And then secondly, I was wondering, Colette, could you just give me a kind of updated commentary or views on visibility in the data center business? How has that changed over the last 3 months? What does that look like as you look through the back half of the calendar year?
Yes. Thanks a lot, Aaron. We are -- we're still in the ramping of the RTX generation. Turing, Turing the current generation that we're in, is the world's first ray tracing GPU. And it fuses -- the RTX technology fuses 3 fundamental technologies: the programmable shader that we introduced a long time ago that revolutionized computer graphics; and we added 2 new technologies. One technology is a ray tracing acceleration core that makes the tracing of rays and looking for intersections between the ray and the scene -- objects in the scene super, super fast. And that -- it's a complicated problem. It's a super-complicated problem. We want it to be running concurrently to shading so that the ray traversal and the shading of the pixels could be done independently and concurrently.
The second thing is we invented this technology to bring AI, artificial intelligence, using this new type of algorithm called deep learning to computer graphics. And one example of its capability is the algorithm we introduced called DLSS, Deep Learning Super Sampling, which allows us to essentially synthesize by learning from previous examples, essentially learning from previous examples of images and remembering it, remembering what beautiful images look like so that when you take a low-resolution image, and you run it through the deep neural network, it synthesizes a high-resolution image that's really, really beautiful. And people have commented that it's even more beautiful than native rendered images at the native resolution. And the benefit is not only is it beautiful, it's also super fast. We essentially nearly doubled the performance of RTX as a result of doing that. So you can have the benefit of ray tracing as well as very high resolution and very high speed. And so that's called RTX.
And Turing is probably not even close, not even 1/3 of the total installed base of all of our GeForce GPUS, which is, as you know, the single-largest installed base of gaming platforms in the world. And so we support this large installed base, and we're in the process of bringing them to the future with RTX. And now with the new console generation coming, every single game developer on the planet is going to be doing ray tracing, and they're going to be creating much, much richer content. And because of multi-platform, cross-platform play and because of the size of the gaming platform, PC gaming platform, it's really important that these game developers bring the latest generation content to PCs, which is great for us.
And then on the data center visibility?
Yes. Let me see if I can answer this one for you. Yes, we have been talking about our visibility of data center. And as you've seen in our Q2 results, you can see that our overall adoption of the NVIDIA computing portfolio has accelerated quite nicely. But keep in mind, we're still really early in the product cycle. A100 is ramping. It's ramping very strong into our existing installed bases but also into new markets. Right now, A100 probably represents less than 1/4 of our data center revenues. So we still have a lot to grow.
We have good visibility looking into Q3 with our hyperscales. We have a little bit more of a mixed outlook in terms of our vertical industries, given a lot of the uncertainty in the market and in terms of the overall economy. On-premises are challenged because of the overall COVID. But remember, industries are quickly and continuing to adopt and move to the overall cloud. But overall, we do expect a very strong Q3.
Your next question comes from the line of C.J. Muse with Evercore ISI.
I guess 2 questions. If I look at your outstanding inventory purchase obligations, grew, I think, 17% sequentially. Is that as you prepare for the September 1 launch? And can you kind of comment on gaming visibility into the back half of the year? And then the second question, Jensen, I know you're very focused on platforms and driving recurring revenues. Would love to hear if there's any particular platforms over the last 3 months where you've made real headway or get you excited, whether Jarvis, Merlin, Spark or whatever.
Yes. Thanks so much, C.J. We're expecting a really strong second half for gaming. I think this may very well be one of the best gaming seasons ever. And the reason for that is because PC gaming has become such a large format. The combination of amazing games like Fortnite and Minecraft and because of the way people game now, their gaming and their e-sporting, even F1 is an e-sport now. They're hanging out with friends. They're using it to create other content. They're using game captures, create art. They're sharing it with the community. It's a broadcast medium. The number of different ways you could game has just really, really exploded. And it works on PCs because all the things that I described require cameras or keyboards or streaming systems or -- and -- but it requires an open system that is multitasking. And so the PC has just become such a large platform for gaming.
And the second thing is that RTX, it's a home run. We really raised the bar with computer graphics, and the games are so beautiful, and it's really, really the next level. It's not been this amazing since we introduced programmable shaders about 15 years ago. And so for the last 15 years, we've been making programmable shaders better and better and better, and it has been getting better. But there's never been a giant leap like this, and RTX brought both artificial intelligence as well as ray tracing to PC gaming.
And then the third factor is the console launch. There's -- people are really -- the game developers are really gearing up for a big leap. And because of the gaming -- because how vibrant the gaming market is right now and how many people around the world is depending on gaming at home. I think it's going to be the most amazing season ever. We're already seeing amazing numbers from our console partner, Nintendo. Switch has -- about to sell more than Super Nintendo, more than all the Famicom, which was one of the best gaming consoles of all time. I mean they're underway to make Switch the most successful gaming platform of all time. And so I'm super excited for them. And so I think it's going to be quite a huge second half of the year.
Your next question comes from the line of Toshiya Hari of Goldman Sachs.
Colette, I felt like I didn't -- I missed C.J.'s second question. Can we jump on and answer it?
I think the question was regarding our inventory purchases on that piece. Is that the part that you're referring to?
Yes. That's the one. Yes.
Yes. Keep in mind, C.J., that when you think about the complexity of the products that we are building, we have extremely long lead times, both in terms of what we produce for the data center, our full systems that we need to do as well as what you are seeing now between the sequential growth between Q2 and Q3 for overall gaming. So all of that is in preparation for the second half. Nothing unusual about it other than, yes, we've got to hit those revenue numbers that are in our Q3 guidance.
Your next question comes from the line of Toshiya Hari with Goldman and Sachs.
I had one for Jensen and another one for Colette. Jensen, just following up on the data center business. As you probably know, quite a few of your peers have been talking about potential digestion of capacity on the part of your hyperscale customers over the next, call it, 6 to 12 months. Curious, is that something that you think about, worry about in your data center business? Or do you have enough idiosyncratic growth drivers like the A100 ramp? And I guess the breadth that you've built within your data center business across compute and networking, are those enough for you to buck the trend within data center over the next 6 to 12 months?
And then the second one for Colette, just on gross margins. You're guiding October quarter gross margins down 50 basis points sequentially. Based on the color that you provided for the individual segments, it looks like mix remains pretty positive. So just curious what's driving the marginal decline in gross margins in the October quarter?
Yes. Thank you. So thanks for the question. The -- our data center trend is really tied to a few factors. One is the proliferation of using deep learning and artificial intelligence and all the services that are in -- by the cloud service providers. And I think it's fair to say that over the last several years, the number of breakthroughs in artificial intelligence has been really terrific. And we're seeing anywhere from 10x, 10x more computational requirement each year to more than that. And so in the last 3 years, we've seen somewhere between 1,000 to 3,000x increase in the size of models, the computational requirement necessary to create these AI models and to deploy these AI models.
And so the #1 trend that we're probably indexed to is the breakthroughs of AI and the usefulness of AI and how people are using it. And one of the -- and I remember C.J.'s question now, and I'll answer this along with that. One of the things that we look for and you should look for is how -- what kind of breakthroughs are based on deep learning and based on AI that these services all demand.
And there are 3 big ones, just gigantic one. Of course, one of them is natural language understanding, the ability to take a very complicated text and use deep learning to create essentially a dimension reduction, it's called deep embedding, dimension reduction on that body of text so that you could use that vector as a way to teach a recommender system, which is the second major breakthrough, the recommender system, how to predict and make a recommendation to somebody. Recommendation on ads and videos, and there are trillions of videos on the web. You need ways to recommend them, both the news and just the amount of information that is going to -- that is in true dynamic form require these recommenders to be instantaneous.
And so the first one is natural language understanding. The second one is the recommender system, gigantic breakthroughs in the last several years. And the third is conversational AI. I mean we're going to have conversational engines that are just super clever, and they can predict what you're about to ask. They're going to predict the right answer for you, make recommendations to you based on the 3 pillars that I just described.
And I haven't even started talking about robotics, the breakthroughs that are happening there with all the factories that need to automate and breakthroughs that we're seeing in self-driving cars, the models there are really improving fast. And so the answer to you, Toshiya, and C.J. are kind of similar, that on the first one, we're indexed to AI. The second, we're indexed to breakthroughs of AI. So that it can continue to consume more and more capability and more technology.
And then the third thing that we're indexed to is the movement of workloads to the cloud. It is now possible to do rendering in the cloud, remote graphics workstations in the cloud. And NVIDIA virtual workstations is in every single cloud. You could do big data analytics in the cloud. And these applications, I've just given you a few applications where you can do scientific computing in the cloud. These applications all have fundamentally different computing architectures.
NVIDIA is the only accelerated architecture that allows you to do microservices for conversational AI and other types of AI applications to scale up applications like high-performance computing, training, big data analytics to virtualize applications like workstations. Our platform is universal, and these 3 facets that I just described are supremely complex, virtualized, microservices-based and scale-up-based. And so these -- bare metal scale-up. And these are complicated, and it's one of the reasons why we bought Mellanox because they're at the core and at the intersection of all of that. The storage, the networking, the security, the virtualization, they're at the intersection of all of that. And I just described 3 dynamics that are very, very powerful and are at the early stages yet. And so those are the things that we're really indexed to.
And then lastly, when somebody adopts -- when we introduce a new platform like Ampere, we're in the beginning of a multiyear product cycle, Ampere is such a gigantic breakthrough. It's the first universal GPU we ever created. It is both able to scale up as well as scale out, scale up as in multi GPUs, scale out is fractionalization, multi-instance GPUs. And it's -- it reduced -- it saves money, tremendous amount of money for people who use it. It speeds up their application. It reduces their TCO. Their TCO value just goes through the roof. And so we're in the beginning of this multiyear cycle and the enthusiasm has been fantastic. This is the fastest ramp we've ever had. And so we're going to keep on racing through the second half.
Okay. And Toshiya, you asked a question regarding our guidance going forward regarding gross margin. And within our Q3 guidance, we have just a small decline in our gross margin from Q2. Most of that is really associated with mix but also a little bit in terms of the ramping of our new Ampere architecture products that we have. So keep in mind, our data center will likely be a lower percentage of total revenue, given the strong overall gaming growth that we expect between Q2 and Q3. Within that gaming growth, keep in mind, consoles are also included, which will continue to be below our company totals average gross margin, and that is expected to be up strongly quarter-over-quarter for our overall console shipments. We're going to be ramping those new architectures over time when we have the ability to expand our gross margin as Ampere GPUs mature, too.
Your next question comes from the line of Stacy Rasgon with Bernstein Research.
I wanted to dig into data center a little bit. This is a question for Colette. So in the quarter, ex Mellanox, data center was up, core data center, maybe 6%, 7%. The guide looks to be roughly similar to that into Q3. Can you talk to us a little bit about what's driving the trajectory? Are you more demand or more supply limited at this point? What does your supply situation look like? And what are the lead times especially on the A100 products for data center look like at this point? Like if you have more capacity available, do you think you'd have like a stronger trajectory than you have right now?
Yes. Stacy, so thanks for the question. Let me first start on our Q3 outlook and what we're seeing. And when we think about our demand and our supply, we're very comfortable with the supply that we have. Keep in mind, our products are quite complex, and a lot of our time is spent in terms of procuring every aspect of that supply over multiple quarters previously. So that's how we work. But we are very confident with the overall supply that we have across the board in data center. Keep in mind that it's not just A100. We are continuing to sell V100 or T4. And we're also bringing new versions of the A100 coming to overall market. So I hope that helps you understand our statements on where are we at in terms of the Q3 guidance. We'll see if Jensen wants to add a little bit more to that.
Well, when we're ramping, we sure love to have more and sooner. And -- but this is our plan, and we're executing to the plan. It is a very complicated product, as Colette mentioned. It is the most complicated.
Got it. Got it. And just a quick follow-up. Within the data center guidance, how do you think about like the core data center sequential growth versus Mellanox?
Yes. So in terms of moving from Q2 to Q3, we believe that most of the actual growth that we will receive in that single -- low single-digit to mid-single-digit growth will likely stem from NVIDIA compute, will be the largest driver of that.
Your next question comes from the line of Joseph Moore with Morgan Stanley.
I wonder if I could ask a longer-term question about the -- how you guys see the importance of process technology. There's been a lot of discussion around that in the CPU domain. But you guys haven't really felt the need to be first on 7 nanometer, and you've done very well. Just how important do you think it is to be early in the new process node? And how does that factor into the cycle of innovation at NVIDIA?
Yes. First of all, thanks, Joe. The process technology is a lot more complex than a number. I think people have simplified it down to almost a ridiculous level, right? And so process technology, we have a really awesome process engineering team, world-class. Everybody will recognize that it's absolutely world-class. And we work with the foundries, we work with TSMC really closely, to make sure that we engineer transistors that are ideal for us and we engineer metallization systems that's ideal for us. It's a complicated thing, and we do it at high part.
Then the second part of it is where architecture, where the process technology and the rest of the design process, the architecture of the chip, and the final analysis, what NVIDIA paid for, is architecture, not procurement of transistors. We're paid for architecture. And there's a vast difference between our architecture and the second best architecture and the rest of the architectures. The difference is incredible. We are easily twice the energy efficiency all the time, irrespective of the number of the -- in the transistor side. And so it must be more complicated than that. And so we put a lot of energy into that, and then the last thing I would say is that going forward, it's really about data center-scale computing. Going forward, you optimize at the data center scale. And the reason why I know this for a fact is because if you're a software engineer, you would be sitting at home right now, and you will write a piece of software that runs on the entire data center in the cloud. You have no idea what's underneath it, nor do you care. And so what you really want is to make sure that, that data center is as high throughput as possible. There are a lot of code in there.
And so what NVIDIA has decided to do over the years is to take our game to a new level. Of course, we start with building the world's best processors, and we use the world's best foundries, and we partnered them very closely to engineer the best process for us. We partner with the best packaging companies to create the world's best packaging. We're the world's first user of cobots. And whether it's -- I think we're -- I'm pretty sure we're still the highest volume by far of 2.5D and 3D packaging.
And so we start from a great chip. We start from a great chip, but we don't end there. That's just the beginning for us. Now we take this thing all the way through systems, the system software, algorithms, networking, all the way up to the entire data center. And the difference is absolutely shocking. We built our data center, Selene, and it took us 4 weeks. We put up Selene in 4 weeks' time. It is the seventh fastest supercomputer in the world, one of the fastest AI supercomputers in the world. It's the most energy-efficient supercomputer in the world, and it broke every single record in MLPerf, and that kind of shows you something about the scale that we work and the complexity of the work that we do. This is the future. It's for -- the future is about data centers.
We have no further questions at this time. Jensen Huang, I turn the call back over to you.
Thank you. The accelerated computing model we pioneered has clearly passed the tipping point. Adopting of NVIDIA computing is accelerating. On this foundation and leveraging one architecture, we have transformed our company in 3 dimensions. First, NVIDIA is a full stack computing platform company, offering the world's most dynamic industries, the chips systems, software and libraries like NVIDIA AI to tackle their most pressing challenges. NVIDIA -- second, NVIDIA is a data center-scale company with capabilities to architect, build and operate the most advanced data centers. The data center is the new computing unit. With this capability, we can create modern data center architectures that are computer maker partners, and then scale out to the world's industry. Third, NVIDIA is a software-defined company today, with rich software content like GeForce NOW, NVIDIA virtual workstation in the cloud, NVIDIA AI and NVIDIA Drive that will add recurring software revenue to our business model.
In the coming years, AI will revolutionize software. Robotics will automate machines, and the virtual and physical worlds will become increasingly integrated through VR and AR. Industry advancements will accelerate, and NVIDIA accelerated computing will play an important role.
Our next GTC will be coming on October 5, again from my kitchen. Join me. I have some exciting developments to share with you. Thanks, everyone.
This concludes today's conference call. You may now disconnect.